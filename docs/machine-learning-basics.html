<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Machine Learning Basics | A RUDIMENTARY GUIDE TO DATA ANALYSIS USING R</title>
  <meta name="description" content="Chapter 11 Machine Learning Basics | A RUDIMENTARY GUIDE TO DATA ANALYSIS USING R" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Machine Learning Basics | A RUDIMENTARY GUIDE TO DATA ANALYSIS USING R" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Machine Learning Basics | A RUDIMENTARY GUIDE TO DATA ANALYSIS USING R" />
  
  
  

<meta name="author" content="Elias Muchineripi Mashayamombe" />


<meta name="date" content="2023-04-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="panel-data-analysis.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data in R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="getting-started-in-r-installations-and-tutorials.html"><a href="getting-started-in-r-installations-and-tutorials.html"><i class="fa fa-check"></i><b>1</b> Getting started in R (Installations and tutorials)</a>
<ul>
<li class="chapter" data-level="1.1" data-path="getting-started-in-r-installations-and-tutorials.html"><a href="getting-started-in-r-installations-and-tutorials.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="getting-started-in-r-installations-and-tutorials.html"><a href="getting-started-in-r-installations-and-tutorials.html#what-is-r"><i class="fa fa-check"></i><b>1.2</b> What is R?</a></li>
<li class="chapter" data-level="1.3" data-path="getting-started-in-r-installations-and-tutorials.html"><a href="getting-started-in-r-installations-and-tutorials.html#downloading-and-installing-r"><i class="fa fa-check"></i><b>1.3</b> Downloading and Installing R</a></li>
<li class="chapter" data-level="1.4" data-path="getting-started-in-r-installations-and-tutorials.html"><a href="getting-started-in-r-installations-and-tutorials.html#getting-started-in-r"><i class="fa fa-check"></i><b>1.4</b> Getting Started in R</a></li>
<li class="chapter" data-level="1.5" data-path="getting-started-in-r-installations-and-tutorials.html"><a href="getting-started-in-r-installations-and-tutorials.html#exercises-1"><i class="fa fa-check"></i><b>1.5</b> Exercises 1:</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="r-basics-and-simulations.html"><a href="r-basics-and-simulations.html"><i class="fa fa-check"></i><b>2</b> R Basics and Simulations</a>
<ul>
<li class="chapter" data-level="2.1" data-path="r-basics-and-simulations.html"><a href="r-basics-and-simulations.html#packages-in-r"><i class="fa fa-check"></i><b>2.1</b> Packages in R</a></li>
<li class="chapter" data-level="2.2" data-path="r-basics-and-simulations.html"><a href="r-basics-and-simulations.html#loops"><i class="fa fa-check"></i><b>2.2</b> LOOPS</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="r-basics-and-simulations.html"><a href="r-basics-and-simulations.html#for-loops"><i class="fa fa-check"></i><b>2.2.1</b> For Loops</a></li>
<li class="chapter" data-level="2.2.2" data-path="r-basics-and-simulations.html"><a href="r-basics-and-simulations.html#while-loops"><i class="fa fa-check"></i><b>2.2.2</b> While Loops</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="r-basics-and-simulations.html"><a href="r-basics-and-simulations.html#simulations"><i class="fa fa-check"></i><b>2.3</b> Simulations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-types-sources-and-wrangling.html"><a href="data-types-sources-and-wrangling.html"><i class="fa fa-check"></i><b>3</b> Data types, sources, and wrangling</a></li>
<li class="chapter" data-level="4" data-path="descriptive-studies.html"><a href="descriptive-studies.html"><i class="fa fa-check"></i><b>4</b> Descriptive studies</a></li>
<li class="chapter" data-level="5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>5</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#regression-history"><i class="fa fa-check"></i><b>5.1</b> Regression History</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#galton-heights-data"><i class="fa fa-check"></i><b>5.1.1</b> Galton Heights Data</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#getting-started-the-simple-regression-model"><i class="fa fa-check"></i><b>5.2</b> Getting Started The Simple Regression Model</a></li>
<li class="chapter" data-level="5.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#ordinary-least-squares-estimations"><i class="fa fa-check"></i><b>5.3</b> Ordinary Least Squares Estimations</a></li>
<li class="chapter" data-level="5.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#simple-linear-regression-assumptions"><i class="fa fa-check"></i><b>5.4</b> Simple Linear Regression Assumptions</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#linearity"><i class="fa fa-check"></i><b>5.4.1</b> Linearity:</a></li>
<li class="chapter" data-level="5.4.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#zero-conditional-mean"><i class="fa fa-check"></i><b>5.4.2</b> Zero conditional mean</a></li>
<li class="chapter" data-level="5.4.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#independence"><i class="fa fa-check"></i><b>5.4.3</b> Independence:</a></li>
<li class="chapter" data-level="5.4.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#homoscedasticity"><i class="fa fa-check"></i><b>5.4.4</b> Homoscedasticity:</a></li>
<li class="chapter" data-level="5.4.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#sample-variation"><i class="fa fa-check"></i><b>5.4.5</b> Sample Variation</a></li>
<li class="chapter" data-level="5.4.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#normality"><i class="fa fa-check"></i><b>5.4.6</b> Normality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>6</b> Multiple Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="multiple-regression.html"><a href="multiple-regression.html#multiple-regression-assumptions"><i class="fa fa-check"></i><b>6.1</b> Multiple Regression Assumptions</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="multiple-regression.html"><a href="multiple-regression.html#linearity-1"><i class="fa fa-check"></i><b>6.1.1</b> Linearity:</a></li>
<li class="chapter" data-level="6.1.2" data-path="multiple-regression.html"><a href="multiple-regression.html#zero-conditional-mean-1"><i class="fa fa-check"></i><b>6.1.2</b> Zero conditional mean</a></li>
<li class="chapter" data-level="6.1.3" data-path="multiple-regression.html"><a href="multiple-regression.html#independence-1"><i class="fa fa-check"></i><b>6.1.3</b> Independence:</a></li>
<li class="chapter" data-level="6.1.4" data-path="multiple-regression.html"><a href="multiple-regression.html#homoscedasticity-1"><i class="fa fa-check"></i><b>6.1.4</b> Homoscedasticity:</a></li>
<li class="chapter" data-level="6.1.5" data-path="multiple-regression.html"><a href="multiple-regression.html#sample-variation-1"><i class="fa fa-check"></i><b>6.1.5</b> Sample Variation</a></li>
<li class="chapter" data-level="6.1.6" data-path="multiple-regression.html"><a href="multiple-regression.html#normality-1"><i class="fa fa-check"></i><b>6.1.6</b> Normality</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="multiple-regression.html"><a href="multiple-regression.html#multiple-regression-equation"><i class="fa fa-check"></i><b>6.2</b> Multiple Regression Equation</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="multiple-regression.html"><a href="multiple-regression.html#anova-table"><i class="fa fa-check"></i><b>6.2.1</b> ANOVA Table</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="multiple-regression.html"><a href="multiple-regression.html#hypothesis-testing"><i class="fa fa-check"></i><b>6.3</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="6.4" data-path="multiple-regression.html"><a href="multiple-regression.html#model-fitness-and-predictive-power"><i class="fa fa-check"></i><b>6.4</b> Model Fitness and Predictive Power</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="multiple-regression.html"><a href="multiple-regression.html#adjusted-r-squared"><i class="fa fa-check"></i><b>6.4.1</b> Adjusted R-Squared</a></li>
<li class="chapter" data-level="6.4.2" data-path="multiple-regression.html"><a href="multiple-regression.html#akaikes-information-criterion-aic"><i class="fa fa-check"></i><b>6.4.2</b> Akaike’s Information Criterion (AIC)</a></li>
<li class="chapter" data-level="6.4.3" data-path="multiple-regression.html"><a href="multiple-regression.html#bayesian-information-criterion-bic"><i class="fa fa-check"></i><b>6.4.3</b> Bayesian Information Criterion (BIC)</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="multiple-regression.html"><a href="multiple-regression.html#model-misspecification"><i class="fa fa-check"></i><b>6.5</b> Model Misspecification</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="multiple-regression.html"><a href="multiple-regression.html#heteroscedasticity"><i class="fa fa-check"></i><b>6.5.1</b> Heteroscedasticity</a></li>
<li class="chapter" data-level="6.5.2" data-path="multiple-regression.html"><a href="multiple-regression.html#serial-correlation"><i class="fa fa-check"></i><b>6.5.2</b> Serial Correlation</a></li>
<li class="chapter" data-level="6.5.3" data-path="multiple-regression.html"><a href="multiple-regression.html#multicollinearity"><i class="fa fa-check"></i><b>6.5.3</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="multiple-regression.html"><a href="multiple-regression.html#influence-analysis"><i class="fa fa-check"></i><b>6.6</b> Influence Analysis</a></li>
<li class="chapter" data-level="6.7" data-path="multiple-regression.html"><a href="multiple-regression.html#regression-analysis-with-qualitative-data"><i class="fa fa-check"></i><b>6.7</b> Regression Analysis With Qualitative Data</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="multiple-regression.html"><a href="multiple-regression.html#dummy-varaibles-in-multiple-regression"><i class="fa fa-check"></i><b>6.7.1</b> Dummy Varaibles In Multiple Regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="logit-and-probit-models.html"><a href="logit-and-probit-models.html"><i class="fa fa-check"></i><b>7</b> Logit and probit Models</a></li>
<li class="chapter" data-level="8" data-path="time-series-analysis.html"><a href="time-series-analysis.html"><i class="fa fa-check"></i><b>8</b> Time Series Analysis</a>
<ul>
<li class="chapter" data-level="8.1" data-path="time-series-analysis.html"><a href="time-series-analysis.html#trend-models"><i class="fa fa-check"></i><b>8.1</b> Trend Models</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="time-series-analysis.html"><a href="time-series-analysis.html#linear-trend-models"><i class="fa fa-check"></i><b>8.1.1</b> Linear Trend Models</a></li>
<li class="chapter" data-level="8.1.2" data-path="time-series-analysis.html"><a href="time-series-analysis.html#log-linear-trend-models"><i class="fa fa-check"></i><b>8.1.2</b> Log-Linear Trend Models</a></li>
<li class="chapter" data-level="8.1.3" data-path="time-series-analysis.html"><a href="time-series-analysis.html#major-limitation-of-trend-models"><i class="fa fa-check"></i><b>8.1.3</b> Major Limitation of Trend Models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="time-series-analysis.html"><a href="time-series-analysis.html#arima-models"><i class="fa fa-check"></i><b>8.2</b> ARIMA Models</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="time-series-analysis.html"><a href="time-series-analysis.html#autoregressive-ar-processes"><i class="fa fa-check"></i><b>8.2.1</b> Autoregressive (AR) Processes</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="time-series-analysis.html"><a href="time-series-analysis.html#random-walk"><i class="fa fa-check"></i><b>8.3</b> Random Walk</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="time-series-analysis.html"><a href="time-series-analysis.html#unit-root-test"><i class="fa fa-check"></i><b>8.3.1</b> Unit Root Test</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="time-series-analysis.html"><a href="time-series-analysis.html#seasonality"><i class="fa fa-check"></i><b>8.4</b> Seasonality</a></li>
<li class="chapter" data-level="8.5" data-path="time-series-analysis.html"><a href="time-series-analysis.html#cointegration"><i class="fa fa-check"></i><b>8.5</b> Cointegration</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="var-and-svar.html"><a href="var-and-svar.html"><i class="fa fa-check"></i><b>9</b> VAR and SVAR</a></li>
<li class="chapter" data-level="10" data-path="panel-data-analysis.html"><a href="panel-data-analysis.html"><i class="fa fa-check"></i><b>10</b> Panel data Analysis</a></li>
<li class="chapter" data-level="11" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html"><i class="fa fa-check"></i><b>11</b> Machine Learning Basics</a>
<ul>
<li class="chapter" data-level="11.1" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html#introduction-to-machine-learning"><i class="fa fa-check"></i><b>11.1</b> Introduction to Machine Learning</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html#some-packages"><i class="fa fa-check"></i><b>11.1.1</b> Some Packages</a></li>
<li class="chapter" data-level="11.1.2" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html#supervised-learning"><i class="fa fa-check"></i><b>11.1.2</b> Supervised Learning</a></li>
<li class="chapter" data-level="11.1.3" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html#unsupervised-learning"><i class="fa fa-check"></i><b>11.1.3</b> Unsupervised Learning</a></li>
<li class="chapter" data-level="11.1.4" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html#deep-learning-and-reinforcement-learning"><i class="fa fa-check"></i><b>11.1.4</b> Deep Learning and Reinforcement Learning</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html#cross-validation"><i class="fa fa-check"></i><b>11.2</b> Cross Validation</a></li>
<li class="chapter" data-level="11.3" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html#machine-learning-algorithms"><i class="fa fa-check"></i><b>11.3</b> Machine Learning Algorithms</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html#supervised-machine-learning-algorithms"><i class="fa fa-check"></i><b>11.3.1</b> Supervised Machine Learning Algorithms</a></li>
<li class="chapter" data-level="11.3.2" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html#supervised-machine-learning-algorithms-1"><i class="fa fa-check"></i><b>11.3.2</b> Supervised Machine Learning Algorithms</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html#deep-learning"><i class="fa fa-check"></i><b>11.4</b> Deep Learning</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html#artificial-neural-networks-ann"><i class="fa fa-check"></i><b>11.4.1</b> Artificial Neural Networks (ANN)</a></li>
<li class="chapter" data-level="11.4.2" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html#deep-learning-nets-dln"><i class="fa fa-check"></i><b>11.4.2</b> Deep Learning Nets (DLN)</a></li>
<li class="chapter" data-level="11.4.3" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html#reinforcement-learning"><i class="fa fa-check"></i><b>11.4.3</b> Reinforcement Learning</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html#dealing-with-large-datasets"><i class="fa fa-check"></i><b>11.5</b> Dealing With Large Datasets</a></li>
<li class="chapter" data-level="11.6" data-path="machine-learning-basics.html"><a href="machine-learning-basics.html#evaluating-model-performance"><i class="fa fa-check"></i><b>11.6</b> Evaluating Model Performance</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A RUDIMENTARY GUIDE TO DATA ANALYSIS USING R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="machine-learning-basics" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number">Chapter 11</span> Machine Learning Basics<a href="machine-learning-basics.html#machine-learning-basics" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>How do we communicate the patterns of desired behavior for baking bread? We can teach:</p>
<ul>
<li>by instruction: “to make bread, you need flour, yeast, salt, and water. Mix them together and knead the dough for 10 minutes.”</li>
<li>by example: “here are six loaves of perfect bread; here, six loaves of burnt bread. see a pattern?”</li>
<li>by reinforcement: “bake bread every day for a month; learn from the texture, color, and taste of each loaf.”</li>
</ul>
<p>Machine learning is the art of programming computers to learn from such sources, and in this case, it would involve teaching a machine learning algorithm to recognize the patterns of successful bread baking based on examples.</p>
<p>Statistical approaches and machine learning techniques are both ways of understanding a process by analyzing observations, but they have different assumptions and methods. Statistical approaches use strict rules and models to explain observations, while machine learning is more flexible and uses large amounts of data to find patterns and make predictions without human input. Machine learning is particularly useful for complex problems with many variables or non-linear systems. This chapter introduces machine learning methodologies but does not get into too much detail.</p>
<div id="introduction-to-machine-learning" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> Introduction to Machine Learning<a href="machine-learning-basics.html#introduction-to-machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are three types of machine learning: supervised learning, unsupervised learning, and deep learning/reinforcement learning.</p>
<div id="some-packages" class="section level3 hasAnchor" number="11.1.1">
<h3><span class="header-section-number">11.1.1</span> Some Packages<a href="machine-learning-basics.html#some-packages" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="supervised-learning" class="section level3 hasAnchor" number="11.1.2">
<h3><span class="header-section-number">11.1.2</span> Supervised Learning<a href="machine-learning-basics.html#supervised-learning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Supervised learning is a type of machine learning technique where the algorithm learns to predict an output value based on input data, while being trained on labeled examples. In supervised learning, the algorithm is provided with a labeled dataset, which means that each example in the dataset is paired with the correct output value. The algorithm then learns to map the input to the output by adjusting its parameters, with the goal of minimizing the difference between the predicted output and the correct output for each labeled example. Once the algorithm has learned from the labeled dataset, it can make predictions on new, unlabeled data by applying the learned mapping function. Examples of supervised learning include predicting housing prices based on features such as location, size, and number of rooms, or classifying emails as spam or not spam based on their content.</p>
<p>Supervised learning is a type of machine learning where the algorithm is trained on a labeled dataset. This means that the input data (X) is already matched with the output data (Y). The algorithm learns to find patterns between X and Y, which it can then use to predict Y values for new X values that it has not seen before. The labeled dataset is used to train the algorithm, which means it learns to identify the relationships between X and Y.</p>
<p>In supervised learning, the Y variable is the target variable, and the X variables are called features. The ML algorithm learns to predict the target variable based on the features. For example, in a credit card fraud detection scenario, the target variable is whether the transaction is fraudulent or not (binary), and the features are transaction characteristics like amount, location, and time. The algorithm learns to predict whether a transaction is fraudulent based on these features.</p>
<p>Supervised learning can be divided into two categories: regression and classification. In regression problems, the target variable is continuous, and the goal is to predict a numerical value. In classification problems, the target variable is categorical, and the goal is to sort observations into different categories. For example, in credit rating, the target variable is ordinal (ranking from low to high creditworthiness), and the goal is to predict the credit rating category based on the features.</p>
<p>Regression and classification use different ML techniques, and there are many different algorithms available. Logistic regression is an example of a classification algorithm, and ordinary least squares is an example of a regression algorithm. Non-linear models can also be used for problems involving large datasets with many features.</p>
<p>The success of supervised learning algorithms is evaluated using test data, where the predicted values are compared to the actual values. If the algorithm can predict the values accurately for new data, it is considered to have learned from the labeled dataset.</p>
</div>
<div id="unsupervised-learning" class="section level3 hasAnchor" number="11.1.3">
<h3><span class="header-section-number">11.1.3</span> Unsupervised Learning<a href="machine-learning-basics.html#unsupervised-learning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Unsupervised learning is a type of machine learning that involves finding patterns in a dataset without prior knowledge of the correct output or labeled data. Unlike supervised learning, there is no predetermined target variable or correct answer to work towards. Instead, unsupervised learning algorithms identify similarities and relationships between data points and group them together based on these similarities.</p>
<p>One common unsupervised learning technique is clustering, where data points are partitioned into groups based on their similarities or distances from each other. Another technique is dimensionality reduction, which aims to reduce the number of variables or features in the dataset while retaining the most relevant information.</p>
<p>In unsupervised learning, the emphasis is on finding hidden structures or patterns within the data that can be used for further analysis or decision-making. For example, unsupervised learning can be used to segment customers based on their purchasing behavior or to identify anomalies or outliers in financial transactions.</p>
</div>
<div id="deep-learning-and-reinforcement-learning" class="section level3 hasAnchor" number="11.1.4">
<h3><span class="header-section-number">11.1.4</span> Deep Learning and Reinforcement Learning<a href="machine-learning-basics.html#deep-learning-and-reinforcement-learning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
</div>
<div id="cross-validation" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> Cross Validation<a href="machine-learning-basics.html#cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="machine-learning-algorithms" class="section level2 hasAnchor" number="11.3">
<h2><span class="header-section-number">11.3</span> Machine Learning Algorithms<a href="machine-learning-basics.html#machine-learning-algorithms" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="supervised-machine-learning-algorithms" class="section level3 hasAnchor" number="11.3.1">
<h3><span class="header-section-number">11.3.1</span> Supervised Machine Learning Algorithms<a href="machine-learning-basics.html#supervised-machine-learning-algorithms" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="penalised-regression" class="section level4 hasAnchor" number="11.3.1.1">
<h4><span class="header-section-number">11.3.1.1</span> Penalised Regression<a href="machine-learning-basics.html#penalised-regression" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="regularization" class="section level5 hasAnchor" number="11.3.1.1.1">
<h5><span class="header-section-number">11.3.1.1.1</span> Regularization<a href="machine-learning-basics.html#regularization" class="anchor-section" aria-label="Anchor link to header"></a></h5>
</div>
</div>
<div id="support-vector-machine" class="section level4 hasAnchor" number="11.3.1.2">
<h4><span class="header-section-number">11.3.1.2</span> Support Vector Machine<a href="machine-learning-basics.html#support-vector-machine" class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
<div id="k-nearest-neighbour" class="section level4 hasAnchor" number="11.3.1.3">
<h4><span class="header-section-number">11.3.1.3</span> K-Nearest Neighbour<a href="machine-learning-basics.html#k-nearest-neighbour" class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
<div id="classification-and-regresion-trees-cart" class="section level4 hasAnchor" number="11.3.1.4">
<h4><span class="header-section-number">11.3.1.4</span> Classification and Regresion Trees (CART)<a href="machine-learning-basics.html#classification-and-regresion-trees-cart" class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
<div id="ensemble" class="section level4 hasAnchor" number="11.3.1.5">
<h4><span class="header-section-number">11.3.1.5</span> Ensemble<a href="machine-learning-basics.html#ensemble" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="random-forest" class="section level5 hasAnchor" number="11.3.1.5.1">
<h5><span class="header-section-number">11.3.1.5.1</span> Random forest<a href="machine-learning-basics.html#random-forest" class="anchor-section" aria-label="Anchor link to header"></a></h5>
</div>
</div>
</div>
<div id="supervised-machine-learning-algorithms-1" class="section level3 hasAnchor" number="11.3.2">
<h3><span class="header-section-number">11.3.2</span> Supervised Machine Learning Algorithms<a href="machine-learning-basics.html#supervised-machine-learning-algorithms-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="dimension-reduction" class="section level4 hasAnchor" number="11.3.2.1">
<h4><span class="header-section-number">11.3.2.1</span> Dimension Reduction<a href="machine-learning-basics.html#dimension-reduction" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="principal-components-analysis-pca" class="section level5 hasAnchor" number="11.3.2.1.1">
<h5><span class="header-section-number">11.3.2.1.1</span> Principal Components Analysis (PCA)<a href="machine-learning-basics.html#principal-components-analysis-pca" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Scree Plot</p>
</div>
</div>
<div id="clustering" class="section level4 hasAnchor" number="11.3.2.2">
<h4><span class="header-section-number">11.3.2.2</span> Clustering<a href="machine-learning-basics.html#clustering" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="k-means-clustering" class="section level5 hasAnchor" number="11.3.2.2.1">
<h5><span class="header-section-number">11.3.2.2.1</span> K-Means Clustering<a href="machine-learning-basics.html#k-means-clustering" class="anchor-section" aria-label="Anchor link to header"></a></h5>
</div>
<div id="hierarchical-clustering" class="section level5 hasAnchor" number="11.3.2.2.2">
<h5><span class="header-section-number">11.3.2.2.2</span> Hierarchical Clustering<a href="machine-learning-basics.html#hierarchical-clustering" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Agglomerative clustering and divisive clustering are two popular approaches to hierarchical clustering, which is a type of unsupervised machine learning used for grouping similar data points together.</p>
<p>Agglomerative clustering, also known as bottom-up clustering, starts with each data point as a separate cluster and then iteratively merges the closest pairs of clusters until all data points belong to a single cluster. This process results in a dendrogram, which is a tree-like structure that shows how the clusters are formed. Agglomerative clustering is computationally efficient and can handle a large number of data points. It is also relatively easy to interpret and visualize the results.</p>
<p>Divisive clustering, also known as top-down clustering, takes the opposite approach. It starts with all data points belonging to a single cluster and then recursively splits the clusters into smaller clusters until each data point belongs to its own cluster. This process also results in a dendrogram, but it can be computationally expensive, especially when dealing with large datasets. Divisive clustering can be more difficult to interpret and visualize than agglomerative clustering, but it can be more effective in identifying clusters that are well-separated.</p>
<p>In summary, agglomerative clustering and divisive clustering are two approaches to hierarchical clustering that differ in the way they group similar data points together. Agglomerative clustering is a bottom-up approach that iteratively merges the closest pairs of clusters, while divisive clustering is a top-down approach that recursively splits the clusters into smaller clusters.</p>
</div>
</div>
</div>
</div>
<div id="deep-learning" class="section level2 hasAnchor" number="11.4">
<h2><span class="header-section-number">11.4</span> Deep Learning<a href="machine-learning-basics.html#deep-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="artificial-neural-networks-ann" class="section level3 hasAnchor" number="11.4.1">
<h3><span class="header-section-number">11.4.1</span> Artificial Neural Networks (ANN)<a href="machine-learning-basics.html#artificial-neural-networks-ann" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="deep-learning-nets-dln" class="section level3 hasAnchor" number="11.4.2">
<h3><span class="header-section-number">11.4.2</span> Deep Learning Nets (DLN)<a href="machine-learning-basics.html#deep-learning-nets-dln" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="reinforcement-learning" class="section level3 hasAnchor" number="11.4.3">
<h3><span class="header-section-number">11.4.3</span> Reinforcement Learning<a href="machine-learning-basics.html#reinforcement-learning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In 2016, DeepMind, a subsidiary of Alphabet Inc., achieved a major breakthrough in artificial intelligence (AI) by creating a computer program named AlphaGo, which defeated the world champion in the ancient Chinese board game Go. This was a significant accomplishment because Go is considered to be one of the most challenging games for AI due to its vast number of possible moves.</p>
<p>Reinforcement learning was one of the primary methods used by AlphaGo to learn how to play the game at an expert level. Reinforcement learning is a subfield of machine learning that involves an agent learning how to make decisions in an environment by receiving feedback in the form of rewards or penalties. In the case of AlphaGo, the environment was the Go board, and the rewards were points earned for winning the game.</p>
<p>The development of AlphaGo consisted of two main stages: training and playing. During the training stage, the program used a combination of supervised learning and reinforcement learning to learn the basic rules and strategies of the game. It was fed a massive dataset of expert-level games to learn from, and its neural networks were trained to predict the next best move given a particular board state.</p>
<p>In the playing stage, AlphaGo used reinforcement learning to improve its gameplay further. It was pitted against itself in numerous games and received rewards for winning and penalties for losing. The program’s neural networks learned from each game, adapting and evolving to improve its gameplay. Through this process, AlphaGo gradually became more skilled and capable of beating even the world’s best Go players.</p>
<p>One of the key innovations that enabled AlphaGo’s success was the use of a technique called Monte Carlo tree search. This algorithm enabled AlphaGo to explore a vast number of possible moves and board states, allowing it to make more informed decisions and ultimately defeat human players.</p>
<p>In conclusion, reinforcement learning played a critical role in enabling AlphaGo to beat the world champion in Go. By training on expert-level games and receiving rewards for winning and penalties for losing, AlphaGo’s neural networks learned to play the game at an expert level. This is a significant achievement in the field of AI and demonstrates the potential of reinforcement learning in solving complex problems.</p>
</div>
</div>
<div id="dealing-with-large-datasets" class="section level2 hasAnchor" number="11.5">
<h2><span class="header-section-number">11.5</span> Dealing With Large Datasets<a href="machine-learning-basics.html#dealing-with-large-datasets" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>R can be used for Big Data analysis, but it requires special techniques and tools to handle large datasets. R is an open-source programming language that is widely used for statistical computing and graphics. However, it was not originally designed for Big Data analysis, and its memory limitations can make it challenging to work with large datasets that do not fit into the memory of a single machine.</p>
<p>To overcome these limitations, several tools and packages have been developed to allow R to work with Big Data. Some of these tools and packages include:</p>
<p>Distributed computing frameworks: R can be integrated with distributed computing frameworks like Apache Hadoop and Apache Spark to handle large datasets that are distributed across multiple machines.</p>
<p>Parallel computing: R provides several packages that support parallel computing, such as parallel, snow, and foreach, which can help speed up computations on large datasets.</p>
<p>Memory-efficient data structures: R also provides packages such as data.table and dplyr that allow for efficient manipulation of large datasets in memory.</p>
<p>Database connectivity: R can connect to various databases, such as MySQL, Oracle, and PostgreSQL, to work with large datasets stored in a database.</p>
<p>Cloud-based solutions: Cloud-based solutions, such as Amazon Web Services (AWS) and Microsoft Azure, offer Big Data services that integrate with R, allowing for large-scale data analysis and processing.</p>
<p>In summary, R can be used for Big Data analysis, but it requires additional tools and techniques to handle large datasets efficiently.</p>
</div>
<div id="evaluating-model-performance" class="section level2 hasAnchor" number="11.6">
<h2><span class="header-section-number">11.6</span> Evaluating Model Performance<a href="machine-learning-basics.html#evaluating-model-performance" class="anchor-section" aria-label="Anchor link to header"></a></h2>


</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="panel-data-analysis.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jtr13/data_txtbook/edit/master/12-ml.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/jtr13/data_txtbook/blob/master/12-ml.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
